{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a38d789",
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "2"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "# transform_pipeline_unified.py\n",
    "# Budget Core Schema (BCS) — robust for Jupyter & CLI, with 0/1 one-hot encoding\n",
    "\n",
    "import os\n",
    "import re\n",
    "import sys\n",
    "import json\n",
    "from zipfile import ZipFile\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# -------- PDF (optional, graceful fallback) --------\n",
    "REPORT_ENABLED = True\n",
    "try:\n",
    "    from reportlab.lib.pagesizes import A4\n",
    "    from reportlab.pdfgen import canvas\n",
    "except Exception:\n",
    "    REPORT_ENABLED = False\n",
    "\n",
    "# ----------------------------\n",
    "# Helpers\n",
    "# ----------------------------\n",
    "\n",
    "def normalize_col(name: str) -> str:\n",
    "    \"\"\"Normalize a column name: replace non-alnum with underscores, collapse repeats, trim.\"\"\"\n",
    "    s = re.sub(r'[^0-9A-Za-z]+', '_', str(name))\n",
    "    s = re.sub(r'_+', '_', s).strip('_')\n",
    "    return s\n",
    "\n",
    "def zscore(series: pd.Series):\n",
    "    \"\"\"Return z-score standardized Series (population std, ddof=0).\"\"\"\n",
    "    mean = float(series.mean())\n",
    "    std = float(series.std(ddof=0))\n",
    "    if std == 0:\n",
    "        # Avoid divide-by-zero: centered values, std reported as 0\n",
    "        return (series - mean), mean, std\n",
    "    return (series - mean) / std, mean, std\n",
    "\n",
    "def compute_vif(X: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Compute VIF for each column by regressing it on the others (OLS via least squares),\n",
    "    adding an intercept term.\n",
    "    \"\"\"\n",
    "    X = X.copy().dropna()\n",
    "    vifs = {}\n",
    "    for col in X.columns:\n",
    "        y = X[col].values\n",
    "        X_others = X.drop(columns=[col]).values\n",
    "        # Add intercept term\n",
    "        X_design = np.column_stack([np.ones(X_others.shape[0]), X_others])\n",
    "        beta, *_ = np.linalg.lstsq(X_design, y, rcond=None)\n",
    "        y_hat = X_design @ beta\n",
    "\n",
    "        ss_res = np.sum((y - y_hat) ** 2)\n",
    "        ss_tot = np.sum((y - y.mean()) ** 2)\n",
    "        R2 = 1 - (ss_res / ss_tot) if ss_tot != 0 else 0.0\n",
    "\n",
    "        vif = 1.0 / (1.0 - R2) if (1 - R2) != 0 else np.inf\n",
    "        vifs[col] = float(vif)\n",
    "    return pd.DataFrame({\"feature\": list(vifs.keys()), \"VIF\": list(vifs.values())})\n",
    "\n",
    "def write_pdf_report(path: str, df: pd.DataFrame, scale_stats: dict,\n",
    "                     vif_orig: pd.DataFrame, vif_reduced: pd.DataFrame,\n",
    "                     outputs: list):\n",
    "    \"\"\"Create a one-page PDF with summary, scaling stats, VIF, and output file locations.\"\"\"\n",
    "    if not REPORT_ENABLED:\n",
    "        # If reportlab isn't available, write a light TXT note instead\n",
    "        with open(path.replace(\".pdf\", \".txt\"), \"w\", encoding=\"utf-8\") as f:\n",
    "            f.write(\"Data Transform Report — Budget Core Schema (BCS)\\n\")\n",
    "            f.write(\"(PDF creation skipped; 'reportlab' not installed)\\n\\n\")\n",
    "            f.write(\"Summary:\\n\")\n",
    "            f.write(\"1) Loaded input CSV; normalized column names.\\n\")\n",
    "            f.write(\"2) Feature Engineering: Total_Spend = R_D_Spend + Marketing_Spend.\\n\")\n",
    "            f.write(\"3) One-Hot (0/1): State_California, State_Florida, State_New York.\\n\")\n",
    "            f.write(\"4) Scaling: z-score for Total_Spend & Administration; saved scaled_features.csv.\\n\")\n",
    "            f.write(\"5) VIF: original vs reduced schema; saved vif_table.csv.\\n\")\n",
    "            f.write(\"6) Final BCS: saved as Processed_BCS.csv.\\n\\n\")\n",
    "            f.write(f\"Rows: {len(df)} | Columns: {df.shape[1]}\\n\")\n",
    "            if \"State\" in df.columns:\n",
    "                states = \", \".join(sorted(df[\"State\"].astype(str).unique()))\n",
    "                f.write(f\"States present: {states}\\n\\n\")\n",
    "            f.write(\"Scaling stats (mean, std):\\n\")\n",
    "            for col, st in scale_stats.items():\n",
    "                f.write(f\" - {col}: mean={st['mean']:.2f}, std={st['std']:.2f}\\n\")\n",
    "            f.write(\"\\nVIF — Original:\\n\")\n",
    "            for _, r in vif_orig.iterrows():\n",
    "                f.write(f\" - {r['feature']}: VIF={r['VIF']:.2f}\\n\")\n",
    "            f.write(\"\\nVIF — Reduced:\\n\")\n",
    "            for _, r in vif_reduced.iterrows():\n",
    "                f.write(f\" - {r['feature']}: VIF={r['VIF']:.2f}\\n\")\n",
    "            f.write(\"\\nOutputs:\\n\")\n",
    "            for p in outputs:\n",
    "                f.write(f\" - {p}\\n\")\n",
    "        return\n",
    "\n",
    "    # PDF path\n",
    "    c = canvas.Canvas(path, pagesize=A4)\n",
    "    width, height = A4\n",
    "    margin = 50\n",
    "    cursor_y = height - margin\n",
    "\n",
    "    def write_line(text, size=11):\n",
    "        nonlocal cursor_y\n",
    "        c.setFont(\"Helvetica\", size)\n",
    "        c.drawString(margin, cursor_y, text)\n",
    "        cursor_y -= 14\n",
    "\n",
    "    # Title\n",
    "    c.setFont(\"Helvetica-Bold\", 16)\n",
    "    c.drawString(margin, cursor_y, \"Data Transform Report — Budget Core Schema (BCS)\")\n",
    "    cursor_y -= 24\n",
    "\n",
    "    # Summary\n",
    "    lines = [\n",
    "        \"1) Loaded input CSV; normalized column names.\",\n",
    "        \"2) Feature Engineering: Total_Spend = R_D_Spend + Marketing_Spend.\",\n",
    "        \"3) One-Hot (0/1): State_California, State_Florida, State_New York.\",\n",
    "        \"4) Scaling: z-score for Total_Spend & Administration; saved scaled_features.csv.\",\n",
    "        \"5) VIF: original schema vs reduced schema; saved vif_table.csv.\",\n",
    "        \"6) Final BCS: saved as Processed_BCS.csv.\",\n",
    "    ]\n",
    "    for line in lines:\n",
    "        write_line(line)\n",
    "\n",
    "    # Basic stats\n",
    "    write_line(\"\")\n",
    "    if \"State\" in df.columns:\n",
    "        states = \", \".join(sorted(df[\"State\"].astype(str).unique()))\n",
    "        write_line(f\"Rows: {len(df):,} | Columns: {df.shape[1]} | States present: {states}\")\n",
    "    else:\n",
    "        write_line(f\"Rows: {len(df):,} | Columns: {df.shape[1]}\")\n",
    "\n",
    "    # Scaling stats\n",
    "    write_line(\"\")\n",
    "    write_line(\"Scaling stats (mean, std):\")\n",
    "    for col, st in scale_stats.items():\n",
    "        write_line(f\" - {col}: mean={st['mean']:.2f}, std={st['std']:.2f}\")\n",
    "\n",
    "    # VIF Original\n",
    "    write_line(\"\")\n",
    "    write_line(\"VIF — Original (R_D_Spend, Administration, Marketing_Spend):\")\n",
    "    for _, r in vif_orig.iterrows():\n",
    "        write_line(f\" - {r['feature']}: VIF={r['VIF']:.2f}\")\n",
    "\n",
    "    # VIF Reduced\n",
    "    write_line(\"\")\n",
    "    write_line(\"VIF — Reduced (Total_Spend, Administration):\")\n",
    "    for _, r in vif_reduced.iterrows():\n",
    "        write_line(f\" - {r['feature']}: VIF={r['VIF']:.2f}\")\n",
    "\n",
    "    # Outputs\n",
    "    write_line(\"\")\n",
    "    write_line(\"Outputs:\")\n",
    "    for p in outputs:\n",
    "        write_line(f\" - {p}\")\n",
    "\n",
    "    c.showPage()\n",
    "    c.save()\n",
    "\n",
    "# ----------------------------\n",
    "# Main pipeline\n",
    "# ----------------------------\n",
    "\n",
    "def run_pipeline(input_csv: str,\n",
    "                 processed_out: str = \"Processed_BCS.csv\",\n",
    "                 scaled_out: str = \"scaled_features.csv\",\n",
    "                 vif_out: str = \"vif_table.csv\",\n",
    "                 report_out: str = \"Data_Transform_Report.pdf\",\n",
    "                 zip_out: str = \"data_transform_bundle.zip\",\n",
    "                 add_alias_scaled: bool = False):\n",
    "    \"\"\"Execute the end-to-end BCS pipeline.\"\"\"\n",
    "    # 0) Validate input\n",
    "    if not os.path.exists(input_csv):\n",
    "        raise FileNotFoundError(f\"Input file not found: {input_csv}\")\n",
    "\n",
    "    # 1) Load\n",
    "    df = pd.read_csv(input_csv, skipinitialspace=True)\n",
    "\n",
    "    # Normalize columns\n",
    "    df.columns = [normalize_col(c) for c in df.columns]\n",
    "    # Expect: R_D_Spend, Administration, Marketing_Spend, State, Profit\n",
    "\n",
    "    # Convert numerics\n",
    "    for col in [\"R_D_Spend\", \"Administration\", \"Marketing_Spend\", \"Profit\"]:\n",
    "        if col in df.columns:\n",
    "            df[col] = pd.to_numeric(df[col], errors=\"coerce\")\n",
    "\n",
    "    # Drop rows missing core numerics\n",
    "    df = df.dropna(subset=[\"R_D_Spend\", \"Administration\", \"Marketing_Spend\", \"Profit\"])\n",
    "\n",
    "    # 2) Feature engineering\n",
    "    df[\"Total_Spend\"] = df[\"R_D_Spend\"].fillna(0) + df[\"Marketing_Spend\"].fillna(0)\n",
    "\n",
    "    # 3) One-Hot (stable schema, 0/1)\n",
    "    for st_col in [\"State_California\", \"State_Florida\", \"State_New York\"]:\n",
    "        df[st_col] = 0  # default 0\n",
    "    if \"State\" in df.columns:\n",
    "        s = df[\"State\"].astype(str)\n",
    "        df.loc[s == \"California\", \"State_California\"] = 1\n",
    "        df.loc[s == \"Florida\", \"State_Florida\"] = 1\n",
    "        df.loc[s == \"New York\", \"State_New York\"] = 1\n",
    "\n",
    "    # 4) Scaling (z-score) — save separately and attach to processed dataset\n",
    "    scale_stats = {}\n",
    "    df[\"Total_Spend_scaled\"], m_ts, s_ts = zscore(df[\"Total_Spend\"])\n",
    "    df[\"Administration_scaled\"], m_ad, s_ad = zscore(df[\"Administration\"])\n",
    "    scale_stats[\"Total_Spend\"] = {\"mean\": m_ts, \"std\": s_ts}\n",
    "    scale_stats[\"Administration\"] = {\"mean\": m_ad, \"std\": s_ad}\n",
    "\n",
    "    # Optional alias for continuity (same as Total_Spend_scaled)\n",
    "    if add_alias_scaled:\n",
    "        df[\"R_D_Marketing_Spend_scaled\"] = df[\"Total_Spend_scaled\"]\n",
    "\n",
    "    # Save scaled-only file\n",
    "    scaled_cols = [\"Total_Spend_scaled\", \"Administration_scaled\"]\n",
    "    if add_alias_scaled:\n",
    "        scaled_cols.append(\"R_D_Marketing_Spend_scaled\")\n",
    "    df[scaled_cols].to_csv(scaled_out, index=False)\n",
    "\n",
    "    # 5) VIF\n",
    "    vif_orig = compute_vif(df[[\"R_D_Spend\", \"Administration\", \"Marketing_Spend\"]])\n",
    "    vif_reduced = compute_vif(df[[\"Total_Spend\", \"Administration\"]])\n",
    "    pd.concat([\n",
    "        vif_orig.assign(schema=\"Original (R&D, Admin, Marketing)\"),\n",
    "        vif_reduced.assign(schema=\"Reduced (Total_Spend, Admin)\")\n",
    "    ]).to_csv(vif_out, index=False)\n",
    "\n",
    "    # 6) Final BCS\n",
    "    bcs_cols = [\n",
    "        \"Total_Spend\", \"Administration\", \"Profit\",\n",
    "        \"State_California\", \"State_Florida\", \"State_New York\",\n",
    "        \"Total_Spend_scaled\", \"Administration_scaled\",\n",
    "    ]\n",
    "    if add_alias_scaled:\n",
    "        bcs_cols.append(\"R_D_Marketing_Spend_scaled\")\n",
    "    df[bcs_cols].to_csv(processed_out, index=False)\n",
    "\n",
    "    # 7) Report (PDF or TXT fallback)\n",
    "    write_pdf_report(\n",
    "        report_out, df, scale_stats, vif_orig, vif_reduced,\n",
    "        outputs=[processed_out, scaled_out, vif_out, report_out if REPORT_ENABLED else report_out.replace(\".pdf\", \".txt\")]\n",
    "    )\n",
    "\n",
    "    # 8) ZIP Bundle\n",
    "    with ZipFile(zip_out, \"w\") as zf:\n",
    "        for p in [processed_out, scaled_out, vif_out, report_out if REPORT_ENABLED else report_out.replace(\".pdf\", \".txt\")]:\n",
    "            if os.path.exists(p):\n",
    "                zf.write(p)\n",
    "\n",
    "    # Console summary\n",
    "    summary = {\n",
    "        \"input\": input_csv,\n",
    "        \"rows\": int(df.shape[0]),\n",
    "        \"cols\": int(df.shape[1]),\n",
    "        \"scale_stats\": scale_stats,\n",
    "        \"vif_original\": vif_orig.to_dict(orient=\"records\"),\n",
    "        \"vif_reduced\": vif_reduced.to_dict(orient=\"records\"),\n",
    "        \"outputs\": [processed_out, scaled_out, vif_out, report_out if REPORT_ENABLED else report_out.replace(\".pdf\", \".txt\"), zip_out],\n",
    "    }\n",
    "    print(json.dumps(summary, indent=2))\n",
    "\n",
    "# ----------------------------\n",
    "# CLI entry (Jupyter-safe)\n",
    "# ----------------------------\n",
    "\n",
    "def main(arg_list=None):\n",
    "    \"\"\"\n",
    "    Jupyter-safe main: if arg_list is None,\n",
    "    - In notebooks: ignore sys.argv to avoid injected args; use defaults.\n",
    "    - In terminal: parse sys.argv[1:] and ignore unknown args.\n",
    "    \"\"\"\n",
    "    import argparse\n",
    "\n",
    "    parser = argparse.ArgumentParser(\n",
    "        description=\"BCS Data Transform Pipeline (0/1 OHE)\",\n",
    "        add_help=True\n",
    "    )\n",
    "    parser.add_argument(\"--in\", dest=\"input_csv\", required=False,\n",
    "                        default=\"Cleaned Dataset - DTD.csv\",\n",
    "                        help=\"Path to input CSV (default: Cleaned Dataset - DTD.csv)\")\n",
    "    parser.add_argument(\"--processed\", dest=\"processed_out\", default=\"Processed_BCS.csv\")\n",
    "    parser.add_argument(\"--scaled\", dest=\"scaled_out\", default=\"scaled_features.csv\")\n",
    "    parser.add_argument(\"--vif\", dest=\"vif_out\", default=\"vif_table.csv\")\n",
    "    parser.add_argument(\"--report\", dest=\"report_out\", default=\"Data_Transform_Report.pdf\")\n",
    "    parser.add_argument(\"--zip\", dest=\"zip_out\", default=\"data_transform_bundle.zip\")\n",
    "    parser.add_argument(\"--alias-scaled\", dest=\"alias_scaled\", action=\"store_true\",\n",
    "                        help=\"Also add R_D_Marketing_Spend_scaled as alias of Total_Spend_scaled\")\n",
    "    # Accept-and-ignore common notebook injections (e.g., --f, -f)\n",
    "    parser.add_argument(\"--f\", dest=\"jupyter_kernel_file\", default=None,\n",
    "                        help=\"(Ignored) Jupyter kernel connection file\")\n",
    "    parser.add_argument(\"-f\", dest=\"jupyter_kernel_file_short\", default=None,\n",
    "                        help=\"(Ignored) Jupyter kernel connection file\")\n",
    "\n",
    "    # Decide which args to parse\n",
    "    if arg_list is None:\n",
    "        in_notebook = (\"ipykernel\" in sys.modules) or (\"JPY_PARENT_PID\" in os.environ)\n",
    "        arg_list = [] if in_notebook else sys.argv[1:]\n",
    "\n",
    "    # Ignore unknown args to prevent SystemExit\n",
    "    args, unknown = parser.parse_known_args(arg_list)\n",
    "\n",
    "    try:\n",
    "        run_pipeline(\n",
    "            input_csv=args.input_csv,\n",
    "            processed_out=args.processed_out,\n",
    "            scaled_out=args.scaled_out,\n",
    "            vif_out=args.vif_out,\n",
    "            report_out=args.report_out,\n",
    "            zip_out=args.zip_out,\n",
    "            add_alias_scaled=args.alias_scaled,\n",
    "        )\n",
    "    except Exception as exc:\n",
    "        print(f\"[Error] {type(exc).__name__}: {exc}\")\n",
    "        print(\"Tip: Check that the input CSV path is correct (use --in \\\"your_file.csv\\\") or call run_pipeline(...) directly.\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n",
    "\n",
    "# ----------------------------\n",
    "# Notebook usage examples\n",
    "# ----------------------------\n",
    "# 1) Direct function call (no CLI, safest in notebooks):\n",
    "# run_pipeline(input_csv=\"Cleaned Dataset - DTD.csv\", add_alias_scaled=True)\n",
    "#\n",
    "# 2) Simulate CLI flags inside a notebook:\n",
    "# main([\n",
    "#   \"--in\", \"Cleaned Dataset - DTD.csv\",\n",
    "#   \"--processed\", \"Processed_BCS.csv\",\n",
    "#   \"--scaled\", \"scaled_features.csv\",\n",
    "#   \"--vif\", \"vif_table.csv\",\n",
    "#   \"--report\", \"Data_Transform_Report.pdf\",\n",
    "#   \"--zip\", \"data_transform_bundle.zip\",\n",
    "#   \"--alias-scaled\"\n",
    "# ])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67324f14",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
